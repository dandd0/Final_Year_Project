{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maze_env import MazeEnv_v0\n",
    "from env_utils.PettingZooEnv_new import PettingZooEnv_new\n",
    "import supersuit\n",
    "import numpy as np\n",
    "from tianshou.env.utils import PettingZooEnv\n",
    "import tianshou as ts\n",
    "from tianshou.utils.net.common import Net\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_train, eps_test = 0.9, 0\n",
    "eps_decay, eps_min = 0.99, 0.1\n",
    "lr, epoch, batch_size = 1e-4, 3, 64\n",
    "gamma, n_step, target_update_freq = 0.9, 3, 320\n",
    "train_num, test_num = 10, 10\n",
    "buffer_size = 30000\n",
    "step_per_epoch, step_per_collect = 10000, 150\n",
    "maze_width = 6\n",
    "\n",
    "#logger = ts.utils.TensorboardLogger(SummaryWriter('log/dqn_no_abs_no_interleaving_cnn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_maze_env(render_mode=None, size=6):\n",
    "    env = MazeEnv_v0.env(render_mode=render_mode, size=size)\n",
    "    env = supersuit.multiagent_wrappers.pad_observations_v0(env)\n",
    "    env = PettingZooEnv_new(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN for the observer\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # assume maze size of 6x6 (13x13 with walls)\n",
    "            nn.Conv2d(3, 12, 3), nn.ReLU(inplace=True), nn.MaxPool2d(2,2,1), # (13-3)+1 = 11, (11-2+1)/2+1 = 6\n",
    "            nn.Conv2d(12, 20, 3), nn.ReLU(inplace=True), nn.MaxPool2d(2,2), # 6-3+1=4, (4-2)/2+1 = 2\n",
    "            nn.Flatten(), nn.Linear(20*2*2, 128), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64), nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs, state=None, info={}):\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float)\n",
    "        self.batch = obs.shape[0]\n",
    "        #logits = self.model(obs.view(batch, -1))\n",
    "        logits = self.model(obs)\n",
    "        return logits, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\maze_env\\envs\\mazelib.py:32: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seed)\n"
     ]
    }
   ],
   "source": [
    "# get the vectorized training/testing environments\n",
    "train_envs = ts.env.DummyVectorEnv([preprocess_maze_env for _ in range(train_num)])\n",
    "test_envs = ts.env.DummyVectorEnv([preprocess_maze_env for _ in range(test_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training with no render environment\n",
    "env = preprocess_maze_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get agent names\n",
    "agents = env.agents\n",
    "\n",
    "# observation spaces/action spaces for the two agents\n",
    "state_shape = env.observation_space.shape or env.observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# define DQN network (128x3 hidden units linear)\n",
    "#net_obs = Net(state_shape, action_shape, [128,128,128])\n",
    "net_obs = Net(state_shape, action_shape, [512, 512, 512])\n",
    "optim_obs = torch.optim.Adam(params=net_obs.parameters(), lr=lr)\n",
    "net_exp = Net(state_shape, action_shape, [16])\n",
    "optim_exp = torch.optim.Adam(params=net_exp.parameters(), lr=lr)\n",
    "\n",
    "# set up policy and collectors\n",
    "agent_observer = ts.policy.DQNPolicy(net_obs, optim_obs, gamma, n_step, target_update_freq)\n",
    "agent_explorer = ts.policy.DQNPolicy(net_exp, optim_exp, gamma, n_step, target_update_freq)\n",
    "agent_policies = [agent_observer, agent_explorer]\n",
    "#agent_policies = [ts.policy.RandomPolicy(), ts.policy.RandomPolicy()] # baseline testing\n",
    "policy = ts.policy.MultiAgentPolicyManager(agent_policies, env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\maze_env\\envs\\mazelib.py:32: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seed)\n"
     ]
    }
   ],
   "source": [
    "# define the training collector (the calc q and step functions)\n",
    "train_collector = ts.data.Collector(\n",
    "    policy, \n",
    "    train_envs, \n",
    "    ts.data.VectorReplayBuffer(buffer_size, train_num),\n",
    "    exploration_noise=True\n",
    ")\n",
    "\n",
    "# define the testing collector\n",
    "test_collector = ts.data.Collector(\n",
    "    policy, \n",
    "    test_envs,\n",
    "    exploration_noise=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up human render environment\n",
    "env_human = preprocess_maze_env(render_mode=\"human\")\n",
    "env_human = ts.env.DummyVectorEnv([lambda: env_human])\n",
    "human_collector = ts.data.Collector(policy, env_human, exploration_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\maze_env\\envs\\mazelib.py:32: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seed)\n",
      "f:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\maze_env\\envs\\mazelib.py:32: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current training epsilon: 0.4636\n",
      "Evaluation Reward at Epoch 1: -349.0\n",
      "Current training epsilon: 0.2364\n",
      "Evaluation Reward at Epoch 2: -355.0\n",
      "Current training epsilon: 0.1206\n",
      "Evaluation Reward at Epoch 3: -354.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to find default font",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\training.ipynb Cell 10\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/training.ipynb#X12sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#human_collector.reset(gym_reset_kwargs={'seed':13})\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/training.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m#np.random.seed()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/training.ipynb#X12sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m human_collector\u001b[39m.\u001b[39mreset_env(gym_reset_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m:i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/training.ipynb#X12sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m human_collector\u001b[39m.\u001b[39;49mcollect(n_episode\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, render\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m60\u001b[39;49m, gym_reset_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m:i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/training.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# reset back to training mode\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/training.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m policy\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\tianshou\\data\\collector.py:323\u001b[0m, in \u001b[0;36mCollector.collect\u001b[1;34m(self, n_step, n_episode, random, render, no_grad, gym_reset_kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mupdate(\n\u001b[0;32m    311\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_fn(\n\u001b[0;32m    312\u001b[0m             obs_next\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mobs_next,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m         )\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    322\u001b[0m \u001b[39mif\u001b[39;00m render:\n\u001b[1;32m--> 323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m render \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misclose(render, \u001b[39m0\u001b[39m):\n\u001b[0;32m    325\u001b[0m         time\u001b[39m.\u001b[39msleep(render)\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\tianshou\\env\\venvs.py:420\u001b[0m, in \u001b[0;36mBaseVectorEnv.render\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_async \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting_id) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironments \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting_id\u001b[39m}\u001b[39;00m\u001b[39m are still stepping, cannot \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrender them now.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m [w\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers]\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\tianshou\\env\\venvs.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_async \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting_id) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironments \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting_id\u001b[39m}\u001b[39;00m\u001b[39m are still stepping, cannot \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrender them now.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m [w\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers]\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\tianshou\\env\\worker\\dummy.py:49\u001b[0m, in \u001b[0;36mDummyEnvWorker.render\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\tianshou\\env\\pettingzoo_env.py:131\u001b[0m, in \u001b[0;36mPettingZooEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 131\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pettingzoo\\utils\\wrappers\\order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcingWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m     EnvLogger\u001b[39m.\u001b[39merror_render_before_reset()\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_rendered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pettingzoo\\utils\\wrappers\\base.py:96\u001b[0m, in \u001b[0;36mBaseWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pettingzoo\\utils\\wrappers\\order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcingWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m     EnvLogger\u001b[39m.\u001b[39merror_render_before_reset()\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_rendered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pettingzoo\\utils\\wrappers\\base.py:96\u001b[0m, in \u001b[0;36mBaseWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pettingzoo\\utils\\wrappers\\base.py:96\u001b[0m, in \u001b[0;36mBaseWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mf:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\maze_env\\envs\\maze.py:527\u001b[0m, in \u001b[0;36mMazeEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset, \u001b[39m\"\u001b[39m\u001b[39mReset the environment before calling .render()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 527\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_frame()\n\u001b[0;32m    528\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mansi\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid)\n",
      "File \u001b[1;32mf:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\maze_env\\envs\\maze.py:445\u001b[0m, in \u001b[0;36mMazeEnv._render_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclock \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mtime\u001b[39m.\u001b[39mClock()\n\u001b[0;32m    444\u001b[0m \u001b[39m# draw the canvas\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m font \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39;49mfreetype\u001b[39m.\u001b[39;49mSysFont(pygame\u001b[39m.\u001b[39;49mfreetype\u001b[39m.\u001b[39;49mget_default_font(), \u001b[39m16\u001b[39;49m)\n\u001b[0;32m    446\u001b[0m canvas \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mSurface((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size\u001b[39m+\u001b[39m\u001b[39m20\u001b[39m))\n\u001b[0;32m    447\u001b[0m canvas\u001b[39m.\u001b[39mfill((\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m)) \u001b[39m# make it white\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pygame\\freetype.py:78\u001b[0m, in \u001b[0;36mSysFont\u001b[1;34m(name, size, bold, italic, constructor)\u001b[0m\n\u001b[0;32m     75\u001b[0m         font\u001b[39m.\u001b[39moblique \u001b[39m=\u001b[39m italic\n\u001b[0;32m     76\u001b[0m         \u001b[39mreturn\u001b[39;00m font\n\u001b[1;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m _SysFont(name, size, bold, italic, constructor)\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pygame\\sysfont.py:436\u001b[0m, in \u001b[0;36mSysFont\u001b[1;34m(name, size, bold, italic, constructor)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m italic \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m gotitalic:\n\u001b[0;32m    434\u001b[0m     set_italic \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m \u001b[39mreturn\u001b[39;00m constructor(fontname, size, set_bold, set_italic)\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\pygame\\freetype.py:73\u001b[0m, in \u001b[0;36mSysFont.<locals>.constructor\u001b[1;34m(fontpath, size, bold, italic)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstructor\u001b[39m(fontpath, size, bold, italic):\n\u001b[1;32m---> 73\u001b[0m     font \u001b[39m=\u001b[39m Font(fontpath, size)\n\u001b[0;32m     74\u001b[0m     font\u001b[39m.\u001b[39mstrong \u001b[39m=\u001b[39m bold\n\u001b[0;32m     75\u001b[0m     font\u001b[39m.\u001b[39moblique \u001b[39m=\u001b[39m italic\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to find default font"
     ]
    }
   ],
   "source": [
    "# manual training loop\n",
    "steps_total = 0\n",
    "steps_n = 0\n",
    "\n",
    "\"\"\"\n",
    "# collect a bunch of random ones\n",
    "policy.policies[agents[0]].set_eps(1)\n",
    "policy.policies[agents[1]].set_eps(1)\n",
    "train_collector.collect(n_step=10000)\n",
    "\"\"\"\n",
    "\n",
    "for i in range(epoch):\n",
    "    steps_n = 0 \n",
    "    \n",
    "    while steps_n < step_per_epoch:\n",
    "        # set epislon for greedy training\n",
    "        policy.policies[agents[0]].set_eps(eps_train)\n",
    "        policy.policies[agents[1]].set_eps(eps_train)\n",
    "\n",
    "        # train the model in training environment\n",
    "        train_collector.reset_env(gym_reset_kwargs={\"options\":{\"n_mazes\":i+1}})\n",
    "        result = train_collector.collect(n_step=step_per_collect, gym_reset_kwargs={\"options\":{\"n_mazes\":i+1}})\n",
    "        steps_n += int(result['n/st'])\n",
    "        steps_total += int(result['n/st'])\n",
    "        \n",
    "        # update the parameters after train_num steps\n",
    "        policy.update(batch_size, train_collector.buffer)\n",
    "\n",
    "        # log\n",
    "        #logger.log_train_data(result, steps_total)\n",
    "        \n",
    "        # set the random training epsilon after each steps per collect\n",
    "        # decay it by specified parameter every\n",
    "        eps_train *= eps_decay\n",
    "        eps_train = np.max([eps_train, eps_min])\n",
    "    \n",
    "    print(f\"Current training epsilon: {np.round(policy.policies[agents[0]].eps, 4)}\")\n",
    "    \n",
    "    # check test results\n",
    "    policy.policies[agents[0]].set_eps(eps_test)\n",
    "    policy.policies[agents[1]].set_eps(eps_test)\n",
    "    test_collector.reset_env(gym_reset_kwargs={\"seed\":i+1})\n",
    "    test_result = test_collector.collect(n_episode=test_num, gym_reset_kwargs={\"options\":{\"maze_type\":\"trivial\"}})\n",
    "\n",
    "    # early stop when policy reaches good enough performance\n",
    "    #if np.mean(test_result['rews'][:,0]) >= reward_threshold:\n",
    "    #    break\n",
    "\n",
    "    # log\n",
    "    #logger.log_test_data(test_result, steps_total)\n",
    "    \n",
    "    print(f\"Evaluation Reward at Epoch {i+1}: {np.mean(test_result['rews'][:,0])}\")\n",
    "\n",
    "    # every 20 epochs render the policy for human-based evalution\n",
    "    if (i % 1) == 0:\n",
    "\n",
    "        # set policy to eval mode\n",
    "        policy.eval()\n",
    "        #human_collector.reset(gym_reset_kwargs={'seed':13})\n",
    "        #np.random.seed()\n",
    "        human_collector.reset_env(gym_reset_kwargs={\"seed\":i+1})\n",
    "        human_collector.collect(n_episode=1, render=1/60, gym_reset_kwargs={\"seed\":i+1})\n",
    "\n",
    "        # reset back to training mode\n",
    "        policy.train()\n",
    "    \n",
    "print('Finished Training.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = MazeEnv_v0.env(size=6, render_mode=\"human\")\n",
    "maze.reset(seed=1)\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maze.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(np.array(maze.exit) - np.array(maze.start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models\n",
    "torch.save(policy.policies[agents[0]].state_dict(), \"model/obs_dqn_no_abs_no_il_cnn.pt\")\n",
    "torch.save(policy.policies[agents[1]].state_dict(), \"model/exp_dqn_no_abs_no_il_linear.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n/ep': 0,\n",
       " 'n/st': 100,\n",
       " 'rews': array([], dtype=float64),\n",
       " 'lens': array([], dtype=int32),\n",
       " 'idxs': array([], dtype=int32),\n",
       " 'rew': 0,\n",
       " 'len': 0,\n",
       " 'rew_std': 0,\n",
       " 'len_std': 0}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.eval()\n",
    "human_collector.reset_env(gym_reset_kwargs={\"seed\":7, \"options\":{\"maze_type\":\"trivial\"}})\n",
    "#np.random.seed()\n",
    "human_collector.collect(n_step=100, render=1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\maze_env\\envs\\maze.py:487: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode.\u001b[0m\n",
      "  gym.logger.warn(\"You are calling render method without specifying any render mode.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n/ep': 0,\n",
       " 'n/st': 20,\n",
       " 'rews': array([], dtype=float64),\n",
       " 'lens': array([], dtype=int32),\n",
       " 'idxs': array([], dtype=int32),\n",
       " 'rew': 0,\n",
       " 'len': 0,\n",
       " 'rew_std': 0,\n",
       " 'len_std': 0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_collector.reset_env(gym_reset_kwargs={\"options\":{\"maze_type\":\"trivial\"}})\n",
    "train_collector.collect(n_step=20, render=1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = preprocess_maze_env(render_mode=\"human\")\n",
    "env = ts.env.DummyVectorEnv([lambda: env])\n",
    "\n",
    "policy.policies[agents[0]].set_eps(1)\n",
    "policy.policies[agents[1]].set_eps(1)\n",
    "collector = ts.data.Collector(policy, env)\n",
    "collector.reset_env(gym_reset_kwargs={'seed':17})\n",
    "np.random.seed()\n",
    "collector.collect(n_episode=1, render=1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = preprocess_maze_env(render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\training.ipynb Cell 20\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/training.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m env\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
