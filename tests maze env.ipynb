{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maze_env import MazeEnv_v0\n",
    "from env_utils.PettingZooEnv_new import PettingZooEnv_new\n",
    "import supersuit\n",
    "import numpy as np\n",
    "from tianshou.env.utils import PettingZooEnv\n",
    "import tianshou as ts\n",
    "from tianshou.utils.net.common import Net\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gymnasium as gym\n",
    "\n",
    "def preprocess_maze_env(render_mode=None, size=6):\n",
    "    env = MazeEnv_v0.env(render_mode=render_mode, size=size)\n",
    "    env = supersuit.multiagent_wrappers.pad_observations_v0(env)\n",
    "    env = PettingZooEnv_new(env)\n",
    "    return env\n",
    "\n",
    "# create a CNN for the observer\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # assume maze size of 6x6 (13x13 with walls)\n",
    "            nn.Conv2d(3, 12, 3), nn.ReLU(inplace=True), nn.MaxPool2d(2,2,1), # (13-3)+1 = 11, (11-2+1)/2+1 = 6\n",
    "            nn.Conv2d(12, 20, 3), nn.ReLU(inplace=True), nn.MaxPool2d(2,2), # 6-3+1=4, (4-2)/2+1 = 2\n",
    "            nn.Flatten(), nn.Linear(20*2*2, 128), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64), nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs, state=None, info={}):\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float)\n",
    "        self.batch = obs.shape[0]\n",
    "        #logits = self.model(obs.view(batch, -1))\n",
    "        logits = self.model(obs)\n",
    "        return logits, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_train, eps_test = 0.9, 0.1\n",
    "eps_decay, eps_min = 0.9995, 0.1\n",
    "lr, epoch, batch_size = 1e-4, 60, 64\n",
    "gamma, n_step, target_update_freq = 0.9, 3, 320\n",
    "train_num, test_num = 10, 10\n",
    "buffer_size = 20000\n",
    "step_per_epoch, step_per_collect = 10000, 150\n",
    "maze_width = 6\n",
    "\n",
    "#logger = ts.utils.TensorboardLogger(SummaryWriter('log/dqn_no_abs_no_interleaving_cnn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vectorized training/testing environments\n",
    "train_envs = ts.env.DummyVectorEnv([preprocess_maze_env for _ in range(train_num)])\n",
    "test_envs = ts.env.DummyVectorEnv([preprocess_maze_env for _ in range(test_num)])\n",
    "\n",
    "env = preprocess_maze_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get agent names\n",
    "agents = env.agents\n",
    "\n",
    "# observation spaces/action spaces for the two agents\n",
    "state_shape = env.observation_space.shape or env.observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# define DQN network (128x3 hidden units linear)\n",
    "#net_obs = Net(state_shape, action_shape, [128,128,128])\n",
    "net_obs = Net(state_shape, action_shape, [512, 512, 512])\n",
    "optim_obs = torch.optim.Adam(params=net_obs.parameters(), lr=lr)\n",
    "net_exp = Net(state_shape, action_shape, [4])\n",
    "optim_exp = torch.optim.Adam(params=net_exp.parameters(), lr=lr)\n",
    "\n",
    "# set up policy and collectors\n",
    "agent_observer = ts.policy.DQNPolicy(net_obs, optim_obs, gamma, n_step, target_update_freq)\n",
    "agent_explorer = ts.policy.DQNPolicy(net_exp, optim_exp, gamma, n_step, target_update_freq)\n",
    "agent_policies = [agent_observer, agent_explorer]\n",
    "#agent_policies = [ts.policy.RandomPolicy(), ts.policy.RandomPolicy()] # baseline testing\n",
    "policy = ts.policy.MultiAgentPolicyManager(agent_policies, env)\n",
    "\n",
    "# define the training collector (the calc q and step functions)\n",
    "train_collector = ts.data.Collector(\n",
    "    policy, \n",
    "    train_envs, \n",
    "    ts.data.VectorReplayBuffer(buffer_size, train_num),\n",
    "    exploration_noise=True\n",
    ")\n",
    "\n",
    "# define the testing collector\n",
    "test_collector = ts.data.Collector(\n",
    "    policy, \n",
    "    test_envs,\n",
    "    exploration_noise=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up human render environment\n",
    "env_human = preprocess_maze_env(render_mode=\"human\")\n",
    "env_human = ts.env.DummyVectorEnv([lambda: env_human])\n",
    "human_collector = ts.data.Collector(policy, env_human, exploration_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = MazeEnv_v0.env(size=6, render_mode='human')\n",
    "maze.reset(options={\"n_mazes\":3})\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Desktop\\University\\Exeter\\ECMM451 Final Year Project\\Final_Year_Project\\tests maze env.ipynb Cell 7\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/tests%20maze%20env.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m human_collector\u001b[39m.\u001b[39mreset_env(gym_reset_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39moptions\u001b[39m\u001b[39m\"\u001b[39m:{\u001b[39m\"\u001b[39m\u001b[39mn_mazes\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m3\u001b[39m}})\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Desktop/University/Exeter/ECMM451%20Final%20Year%20Project/Final_Year_Project/tests%20maze%20env.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m human_collector\u001b[39m.\u001b[39;49mcollect(n_episode\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, render\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m60\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Dickson Lim\\anaconda3\\lib\\site-packages\\tianshou\\data\\collector.py:325\u001b[0m, in \u001b[0;36mCollector.collect\u001b[1;34m(self, n_step, n_episode, random, render, no_grad, gym_reset_kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mrender()\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m render \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misclose(render, \u001b[39m0\u001b[39m):\n\u001b[1;32m--> 325\u001b[0m         time\u001b[39m.\u001b[39;49msleep(render)\n\u001b[0;32m    327\u001b[0m \u001b[39m# add data into the buffer\u001b[39;00m\n\u001b[0;32m    328\u001b[0m ptr, ep_rew, ep_len, ep_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39madd(\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, buffer_ids\u001b[39m=\u001b[39mready_env_ids\n\u001b[0;32m    330\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "human_collector.reset_env(gym_reset_kwargs={\"options\":{\"n_mazes\":3}})\n",
    "human_collector.collect(n_episode=3, render=1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_human.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
