Evaluation Reward at Epoch 1. Obs: -0.997, Exp: -0.006
Test Mazes results: [0]
Evaluation Reward at Epoch 2. Obs: -0.997, Exp: 0.0
Evaluation Reward at Epoch 3. Obs: -0.994, Exp: -0.017
Evaluation Reward at Epoch 4. Obs: -0.997, Exp: 0.0
Evaluation Reward at Epoch 5. Obs: -0.997, Exp: 0.0
Evaluation Reward at Epoch 6. Obs: -0.994, Exp: -0.017
Evaluation Reward at Epoch 7. Obs: -0.997, Exp: -0.023
Evaluation Reward at Epoch 8. Obs: -0.997, Exp: 0.0
Evaluation Reward at Epoch 9. Obs: -0.997, Exp: -0.011
Evaluation Reward at Epoch 10. Obs: -0.994, Exp: -0.006
Evaluation Reward at Epoch 11. Obs: -0.994, Exp: -0.034
Test Mazes results: [0]
Evaluation Reward at Epoch 12. Obs: -0.997, Exp: -0.006
Evaluation Reward at Epoch 13. Obs: -0.997, Exp: -0.006
Evaluation Reward at Epoch 14. Obs: -0.997, Exp: 0.0
Evaluation Reward at Epoch 15. Obs: -0.994, Exp: -0.034
Evaluation Reward at Epoch 16. Obs: -0.997, Exp: -0.006
Evaluation Reward at Epoch 17. Obs: -0.994, Exp: -0.017
Evaluation Reward at Epoch 18. Obs: -0.997, Exp: -0.017
Evaluation Reward at Epoch 19. Obs: -0.994, Exp: -0.006
Evaluation Reward at Epoch 20. Obs: -0.997, Exp: -0.006
Evaluation Reward at Epoch 21. Obs: 0.98, Exp: -0.039
Test Mazes results: [1]
Agents solved the current maze and all previous mazes. Current number of mazes: 1.
Solved all mazes on epoch 21.
Evaluation Reward at Epoch 1. Obs: -0.992, Exp: -0.034
Test Mazes results: [0]
Evaluation Reward at Epoch 2. Obs: -0.994, Exp: -0.975
Evaluation Reward at Epoch 3. Obs: -0.994, Exp: -0.992
Evaluation Reward at Epoch 4. Obs: -0.997, Exp: -1.003
Evaluation Reward at Epoch 5. Obs: -0.997, Exp: -0.997
Evaluation Reward at Epoch 6. Obs: -0.997, Exp: -0.997
Evaluation Reward at Epoch 7. Obs: -0.961, Exp: -0.93
Evaluation Reward at Epoch 8. Obs: -0.966, Exp: -0.766
Evaluation Reward at Epoch 9. Obs: -0.966, Exp: -0.901
Evaluation Reward at Epoch 10. Obs: -0.994, Exp: -0.986
Evaluation Reward at Epoch 11. Obs: -0.961, Exp: -0.654
Test Mazes results: [0]
Evaluation Reward at Epoch 12. Obs: -0.997, Exp: -0.992
Evaluation Reward at Epoch 13. Obs: -0.997, Exp: -0.986
Evaluation Reward at Epoch 14. Obs: -0.969, Exp: -0.992
Evaluation Reward at Epoch 15. Obs: -0.997, Exp: -1.003
Evaluation Reward at Epoch 16. Obs: -0.969, Exp: -0.992
Evaluation Reward at Epoch 17. Obs: -0.969, Exp: -1.003
Evaluation Reward at Epoch 18. Obs: -0.969, Exp: -0.665
Evaluation Reward at Epoch 19. Obs: -0.966, Exp: -0.823
Evaluation Reward at Epoch 20. Obs: -0.969, Exp: -1.003
Evaluation Reward at Epoch 21. Obs: -0.997, Exp: -0.992
Test Mazes results: [0]
Evaluation Reward at Epoch 22. Obs: -0.966, Exp: -0.997
Evaluation Reward at Epoch 23. Obs: -0.969, Exp: -0.992
Evaluation Reward at Epoch 24. Obs: -0.969, Exp: -0.997
Evaluation Reward at Epoch 25. Obs: -0.969, Exp: -0.992
Evaluation Reward at Epoch 26. Obs: -0.966, Exp: -0.98
Evaluation Reward at Epoch 27. Obs: -0.997, Exp: -0.997
Evaluation Reward at Epoch 28. Obs: -0.969, Exp: -0.862
Evaluation Reward at Epoch 29. Obs: -0.969, Exp: -0.513
Evaluation Reward at Epoch 30. Obs: -0.969, Exp: -0.997
Evaluation Reward at Epoch 31. Obs: -0.975, Exp: -1.003
Test Mazes results: [0]
Evaluation Reward at Epoch 32. Obs: -0.969, Exp: -0.992
Evaluation Reward at Epoch 33. Obs: -0.966, Exp: -0.992
Evaluation Reward at Epoch 34. Obs: -0.966, Exp: -0.524
Evaluation Reward at Epoch 35. Obs: -0.997, Exp: -0.507
Evaluation Reward at Epoch 36. Obs: -0.969, Exp: -0.518
Evaluation Reward at Epoch 37. Obs: -0.969, Exp: -0.952
Evaluation Reward at Epoch 38. Obs: -0.997, Exp: -0.501
Evaluation Reward at Epoch 39. Obs: -0.969, Exp: -0.997
Evaluation Reward at Epoch 40. Obs: -0.969, Exp: -0.513
Evaluation Reward at Epoch 41. Obs: -0.997, Exp: -0.501
Test Mazes results: [0]
Evaluation Reward at Epoch 42. Obs: -0.969, Exp: -0.513
Evaluation Reward at Epoch 43. Obs: -0.997, Exp: -0.513
Evaluation Reward at Epoch 44. Obs: -0.969, Exp: -0.513
Evaluation Reward at Epoch 45. Obs: -0.966, Exp: -0.93
Evaluation Reward at Epoch 46. Obs: -0.997, Exp: -0.501
Evaluation Reward at Epoch 47. Obs: -0.997, Exp: -0.513
Evaluation Reward at Epoch 48. Obs: -0.966, Exp: -0.524
Evaluation Reward at Epoch 49. Obs: -0.969, Exp: -0.513
Evaluation Reward at Epoch 50. Obs: -0.969, Exp: -0.524
Evaluation Reward at Epoch 51. Obs: -0.969, Exp: -0.513
Test Mazes results: [0]
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "int", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "int", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"shape": "", "count": 1, "type": "dict"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float64", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
{"CNN": "type", "F": "module", "MazeEnv_v0": "module", "Net": "type", "PettingZooEnv": "ABCMeta", "PettingZooEnv_new": "ABCMeta", "SummaryWriter": "type", "action_shape": "int", "agent0_eps": "DQNPolicy", "agent1_aps": "DQNPolicy", "agent_explorer": "DQNPolicy", "agent_observer": "DQNPolicy", "agent_policies": "list", "agents": "list", "batch_size": "int", "buffer_size": "int", "env": "PettingZooEnv_new", "env_human": "DummyVectorEnv", "ep_per_collect": "int", "epoch": "int", "epochs": "int", "eps_decay": "float", "eps_min": "float", "eps_prev": "float64", "eps_test": "float", "eps_train": "float", "gamma": "float", "gym": "module", "high_eps_run": "bool", "human_collector": "Collector", "interleave_training": "function", "log_data": "dict", "lr": "float", "maze": "OrderEnforcingWrapper", "maze_width": "int", "mazes": "int", "n_mazes": "int", "n_step": "int", "net_exp": "Net", "net_obs": "CNN", "nn": "module", "np": "module", "obs_train": "bool", "optim_exp": "Adam", "optim_obs": "Adam", "passed_mazes": "bool", "policy": "MultiAgentPolicyManager", "preprocess_maze_env": "function", "result": "dict", "run": "Run", "seed": "int", "state_shape": "tuple", "step_per_collect": "int", "step_per_epoch": "int", "steps_n": "int", "steps_total": "int", "supersuit": "module", "target_update_freq": "int", "test_collector": "Collector", "test_envs": "DummyVectorEnv", "test_mazes": "list", "test_num": "int", "test_result": "dict", "threshold_rew": "float", "torch": "module", "total_mazes": "int", "train_collector": "Collector", "train_envs": "DummyVectorEnv", "train_num": "int", "ts": "module", "wandb": "module"}
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
c:\Users\Dickson Lim\anaconda3\lib\site-packages\wandb\sdk\lib\ipython.py:70: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display
  from IPython.core.display import HTML, display  # type: ignore